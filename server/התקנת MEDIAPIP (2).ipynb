{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cab9158f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 's' to save the image and exit, or 'q' to exit without saving.\n",
      "Image saved as 'ca,ptured_image.png'\n",
      "0.12518852218196064\n",
      "0.4254525303840637\n",
      "0.4246906042098999\n",
      "0.7979944944381714\n",
      "0.8040807247161865\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mediapipe import solutions\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "def draw_landmarks_on_image(rgb_image, detection_result):\n",
    "    face_landmarks_list = detection_result.face_landmarks\n",
    "    annotated_image = np.copy(rgb_image)\n",
    "    for idx in range(len(face_landmarks_list)):\n",
    "        face_landmarks = face_landmarks_list[idx]\n",
    "        face_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "        face_landmarks_proto.landmark.extend([\n",
    "            landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in face_landmarks\n",
    "        ])\n",
    "        # ×¦×™×•×¨ ×”× ×§×•×“×•×ª ×•×”×—×™×‘×•×¨×™×\n",
    "        solutions.drawing_utils.draw_landmarks(\n",
    "            image=annotated_image,\n",
    "            landmark_list=face_landmarks_proto,\n",
    "            connections=mp.solutions.face_mesh.FACEMESH_TESSELATION,\n",
    "            landmark_drawing_spec=None,\n",
    "            connection_drawing_spec=mp.solutions.drawing_styles\n",
    "            .get_default_face_mesh_tesselation_style())\n",
    "        solutions.drawing_utils.draw_landmarks(\n",
    "            image=annotated_image,\n",
    "            landmark_list=face_landmarks_proto,\n",
    "            connections=mp.solutions.face_mesh.FACEMESH_CONTOURS,\n",
    "            landmark_drawing_spec=None,\n",
    "            connection_drawing_spec=mp.solutions.drawing_styles\n",
    "            .get_default_face_mesh_contours_style())\n",
    "        solutions.drawing_utils.draw_landmarks(\n",
    "            image=annotated_image,\n",
    "            landmark_list=face_landmarks_proto,\n",
    "            connections=mp.solutions.face_mesh.FACEMESH_IRISES,\n",
    "            landmark_drawing_spec=None,\n",
    "            connection_drawing_spec=mp.solutions.drawing_styles\n",
    "            .get_default_face_mesh_iris_connections_style())\n",
    "        # âœ… 473,263,362×”×•×¡×¤×ª ××¡×¤×¨×™× ×œ××¡×¤×¨ × ×§×•×“×•×ª ×‘×•-×–×× ×™×ª\n",
    "        landmark_indices = [] # ×¨×©×™××ª ×”××™× ×“×§×¡×™× ×©×‘×¨×¦×•× ×š ×œ×”×¦×™×’\n",
    "        for landmark_index in landmark_indices:\n",
    "            if landmark_index < len(face_landmarks):\n",
    "                landmark = face_landmarks[landmark_index]\n",
    "                h, w, _ = annotated_image.shape  # ×’×•×“×œ ×”×ª××•× ×”\n",
    "                cx, cy = int(landmark.x * w), int(landmark.y * h)  # ×”××¨×ª ×§×•××•×¨×“×™× ×˜×•×ª ×™×—×¡×™×•×ª ×œ×¤×™×§×¡×œ×™×\n",
    "                # ×”×’×“×¨×•×ª ×¤×•× ×˜ ×§×˜×Ÿ ×•××“×•×™×§\n",
    "                text = str(landmark_index)\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                font_scale = 0.25  # ××¡×¤×¨ ×§×˜×Ÿ ×××•×“\n",
    "                thickness = 1\n",
    "                text_size = cv2.getTextSize(text, font, font_scale, thickness)[0]\n",
    "                # ×—×™×©×•×‘ × ×§×•×“×ª ×”×”×ª×—×œ×” - ××ª×—×ª ×œ× ×§×•×“×” ×›×“×™ ×œ× ×œ×”×¡×ª×™×¨ ××•×ª×”\n",
    "                text_x = cx - text_size[0] //2\n",
    "                text_y = cy + text_size[1] +2# ××–×™×– ××¢×˜ ××ª×—×ª ×œ× ×§×•×“×”\n",
    "                # âœ… ×”×•×¡×¤×ª ×¨×§×¢ ×©×—×•×¨ ×××—×•×¨×™ ×”××¡×¤×¨ ×œ×©×™×¤×•×¨ ×”×‘×”×™×¨×•×ª\n",
    "                cv2.putText(annotated_image, text, (text_x, text_y), font, font_scale, (0, 0, 0), thickness + 2, cv2.LINE_AA)  # ×¨×§×¢ ×©×—×•×¨\n",
    "                cv2.putText(annotated_image, text, (text_x, text_y), font, font_scale, (0, 255, 0), thickness, cv2.LINE_AA)  # ×˜×§×¡×˜ ×™×¨×•×§\n",
    "    return annotated_image\n",
    "# ×¤×ª×™×—×ª ××¦×œ××”\n",
    "cap = cv2.VideoCapture(0)  # 0 ×¢×‘×•×¨ ××¦×œ××” ×¨××©×™×ª\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open camera.\")\n",
    "    exit()\n",
    "# ×§×¨×™××ª ×¤×¨×™×™××™× ××”××¦×œ××”\n",
    "print(\"Press 's' to save the image and exit, or 'q' to exit without saving.\")\n",
    "while True:\n",
    "    ret, frame = cap.read()  # ×§×¨×™××ª ×¤×¨×™×™× ××”××¦×œ××”\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame.\")\n",
    "        break\n",
    "    cv2.imshow(\"Camera\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('s'):  # ×©××™×¨×ª ×ª××•× ×”\n",
    "        cv2.imwrite(\"captured_image.png\", frame)\n",
    "        print(\"Image saved as 'ca,ptured_image.png'\")\n",
    "        break\n",
    "    elif key == ord('q'):  # ×™×¦×™××”\n",
    "        print(\"Exiting without saving.\")\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "# ×§×¨×™××ª ×”×ª××•× ×” ×©× ×©××¨×”\n",
    "image_format = mp.ImageFormat.SRGB\n",
    "image = mp.Image(image_format, np.array(frame))\n",
    "# ×™×¦×™×¨×ª ××•×“×œ ×œ×–×™×”×•×™ × ×§×•×“×•×ª ×‘×¤× ×™×\n",
    "base_options = python.BaseOptions(model_asset_path=r'C:\\face_landmarker_v2_with_blendshapes.task')\n",
    "options = vision.FaceLandmarkerOptions(base_options=base_options,\n",
    "                                       output_face_blendshapes=True,\n",
    "                                       output_facial_transformation_matrixes=True,\n",
    "                                       num_faces=1)\n",
    "detector = vision.FaceLandmarker.create_from_options(options)\n",
    "# ×–×™×”×•×™ × ×§×•×“×•×ª ×”×¤× ×™× ×‘×ª××•× ×”\n",
    "detection_result = detector.detect(image)\n",
    "# ×¦×™×•×¨ ×”× ×§×•×“×•×ª ×•×”×•×¡×¤×ª ×”××¡×¤×¨×™×\n",
    "annotated_image = draw_landmarks_on_image(image.numpy_view(), detection_result)\n",
    "# ×”×¦×’×ª ×”×ª××•× ×” ×¢× ×”××¡×¤×¨×™×\n",
    "cv2.imshow(\"Annotated Image\", cv2.cvtColor(annotated_image, cv2.COLOR_RGB2BGR))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "print(((1-detection_result.face_landmarks[0][263].y)-(1-detection_result.face_landmarks[0][359].y))/((detection_result.face_landmarks[0][263].x-detection_result.face_landmarks[0][359].x)))\n",
    "print(detection_result.face_landmarks[0][263].y)\n",
    "print(detection_result.face_landmarks[0][359].y)\n",
    "print(detection_result.face_landmarks[0][263].x)\n",
    "print(detection_result.face_landmarks[0][359].x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88cd34b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'draw_center_box' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 84\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     83\u001b[0m angles \u001b[38;5;241m=\u001b[39m estimate_angles(frame)\n\u001b[1;32m---> 84\u001b[0m \u001b[43mdraw_center_box\u001b[49m(frame)\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m angles:\n\u001b[0;32m     87\u001b[0m     pitch, yaw, roll \u001b[38;5;241m=\u001b[39m angles\n",
      "\u001b[1;31mNameError\u001b[0m: name 'draw_center_box' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "# ×”×’×“×¨×•×ª FaceMesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=False)\n",
    "\n",
    "# ×¤×•× ×§×¦×™×” ×œ×–×™×”×•×™ × ×§×•×“×•×ª ×—×©×•×‘×•×ª ×‘×¤× ×™×\n",
    "def get_points(landmarks, w, h):\n",
    "    return np.array([\n",
    "        [landmarks[1].x * w, landmarks[1].y * h],     # ××£\n",
    "        [landmarks[33].x * w, landmarks[33].y * h],   # ×¢×™×Ÿ ×©×××œ\n",
    "        [landmarks[263].x * w, landmarks[263].y * h], # ×¢×™×Ÿ ×™××™×Ÿ\n",
    "        [landmarks[61].x * w, landmarks[61].y * h],   # ×¤×” ×©×××œ\n",
    "        [landmarks[291].x * w, landmarks[291].y * h], # ×¤×” ×™××™×Ÿ\n",
    "        [landmarks[199].x * w, landmarks[199].y * h], # ×¡× ×˜×¨\n",
    "    ], dtype=np.float64)\n",
    "\n",
    "model_points = np.array([\n",
    "    [0.0, 0.0, 0.0],\n",
    "    [-30.0, -30.0, -30.0],\n",
    "    [30.0, -30.0, -30.0],\n",
    "    [-25.0, 30.0, -30.0],\n",
    "    [25.0, 30.0, -30.0],\n",
    "    [0.0, 70.0, -50.0],\n",
    "])\n",
    "\n",
    "# ×—×™×©×•×‘ ×–×•×•×™×•×ª ×”×¨××©\n",
    "def estimate_angles(frame):\n",
    "    h, w, _ = frame.shape\n",
    "    results = face_mesh.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    if not results.multi_face_landmarks:\n",
    "        return None\n",
    "    landmarks = results.multi_face_landmarks[0].landmark\n",
    "    image_points = get_points(landmarks, w, h)\n",
    "\n",
    "    focal_length = w\n",
    "    center = (w / 2, h / 2)\n",
    "    camera_matrix = np.array([\n",
    "        [focal_length, 0, center[0]],\n",
    "        [0, focal_length, center[1]],\n",
    "        [0, 0, 1]\n",
    "    ], dtype=\"double\")\n",
    "\n",
    "    dist_coeffs = np.zeros((4, 1))\n",
    "    _, rvec, tvec = cv2.solvePnP(model_points, image_points, camera_matrix, dist_coeffs)\n",
    "    rotation_mat, _ = cv2.Rodrigues(rvec)\n",
    "    angles, _, _, _, _, _ = cv2.RQDecomp3x3(rotation_mat)\n",
    "    return angles  # pitch, yaw, roll\n",
    "\n",
    "# ×‘×“×™×§×ª ×™×©×¨×•×ª\n",
    "def is_straight(pitch, yaw, roll, tol=12):\n",
    "    return abs(pitch) < tol and abs(yaw) < tol and abs(roll) < tol\n",
    "\n",
    "# ×¦×™×•×¨ ××¡×’×¨×ª ×¢×–×¨\n",
    "# def draw_center_box(frame):\n",
    "#     h, w = frame.shape[:2]\n",
    "#     box_w, box_h = int(w * 0.4), int(h * 0.6)\n",
    "#     x1, y1 = (w - box_w) // 2, (h - box_h) // 2\n",
    "#     x2, y2 = x1 + box_w, y1 + box_h\n",
    "#     cv2.rectangle(frame, (x1, y1), (x2, y2), (200, 255, 200), 2)\n",
    "#     return (x1, y1, x2, y2)\n",
    "\n",
    "# ×ª×™×¢×•×“ ××•×˜×•××˜×™\n",
    "def auto_capture(frame):\n",
    "    ts = int(time.time())\n",
    "    filename = f\"face_capture_{ts}.jpg\"\n",
    "    cv2.imwrite(filename, frame)\n",
    "    print(f\"âœ” × ×©××¨×” ×ª××•× ×”: {filename}\")\n",
    "\n",
    "# ×”×ª×—×œ×ª ×¦×™×œ×•× ×•×™×“××•\n",
    "cap = cv2.VideoCapture(0)\n",
    "captured = False\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    angles = estimate_angles(frame)\n",
    "    draw_center_box(frame)\n",
    "\n",
    "    if angles:\n",
    "        pitch, yaw, roll = angles\n",
    "        aligned = is_straight(pitch, yaw, roll)\n",
    "\n",
    "        status = f\"P={pitch:.1f} Y={yaw:.1f} R={roll:.1f}\"\n",
    "        color = (0, 255, 0) if aligned else (0, 0, 255)\n",
    "        msg = \"âœ… ×™×©×¨ - ××¦×œ×!\" if aligned else \"âŒ ×œ× ×™×©×¨\"\n",
    "\n",
    "        cv2.putText(frame, status + \" \" + msg, (20, 40),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "\n",
    "        if aligned and not captured:\n",
    "            auto_capture(frame)\n",
    "            captured = True\n",
    "            break\n",
    "    cv2.imshow(\"××¦×œ××” - ×™×™×©×•×¨ ×¤× ×™×\", frame)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('r'):\n",
    "        captured = False  # ××™×¤×•×¡ ×¦×™×œ×•×\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78b70064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ” ×ª××•× ×” × ×©××¨×”: captured_face_1746577220.jpg\n",
      "âœ” ×ª××•× ×” × ×©××¨×”: captured_face_1746577234.jpg\n",
      "âœ” ×ª××•× ×” × ×©××¨×”: captured_face_1746577242.jpg\n",
      "âœ” ×ª××•× ×” × ×©××¨×”: captured_face_1746577248.jpg\n",
      "âœ” ×ª××•× ×” × ×©××¨×”: captured_face_1746577257.jpg\n",
      "Pitch=-16.0, Yaw=-0.3, Roll=-0.0, Straight=False\n",
      "âŒ ×”×ª××•× ×” ×œ× ×™×©×¨×”\n",
      "Pitch=-40.3, Yaw=-1.4, Roll=1.6, Straight=False\n",
      "âŒ ×”×ª××•× ×” ×œ× ×™×©×¨×”\n",
      "Pitch=-5.4, Yaw=-2.0, Roll=0.3, Straight=True\n",
      "âœ” ×ª××•× ×” × ×©××¨×”: valid_face_1746577285.jpg\n",
      "Pitch=-13.0, Yaw=-0.3, Roll=-0.3, Straight=True\n",
      "âœ” ×ª××•× ×” × ×©××¨×”: valid_face_1746577294.jpg\n",
      "Pitch=-32.4, Yaw=8.2, Roll=-1.1, Straight=False\n",
      "âŒ ×”×ª××•× ×” ×œ× ×™×©×¨×”\n",
      "Pitch=-30.1, Yaw=1.6, Roll=2.1, Straight=False\n",
      "âŒ ×”×ª××•× ×” ×œ× ×™×©×¨×”\n",
      "Pitch=-27.9, Yaw=-1.3, Roll=-2.6, Straight=False\n",
      "âŒ ×”×ª××•× ×” ×œ× ×™×©×¨×”\n",
      "Pitch=43.3, Yaw=-2.3, Roll=-2.0, Straight=False\n",
      "âŒ ×”×ª××•× ×” ×œ× ×™×©×¨×”\n",
      "Pitch=39.1, Yaw=0.1, Roll=-4.2, Straight=False\n",
      "âŒ ×”×ª××•× ×” ×œ× ×™×©×¨×”\n",
      "Pitch=-23.2, Yaw=0.3, Roll=-2.1, Straight=False\n",
      "âŒ ×”×ª××•× ×” ×œ× ×™×©×¨×”\n",
      "Pitch=-24.5, Yaw=0.3, Roll=0.1, Straight=False\n",
      "âŒ ×”×ª××•× ×” ×œ× ×™×©×¨×”\n",
      "Pitch=23.6, Yaw=-0.4, Roll=-0.6, Straight=False\n",
      "âŒ ×”×ª××•× ×” ×œ× ×™×©×¨×”\n",
      "Pitch=-21.9, Yaw=-0.2, Roll=-1.3, Straight=False\n",
      "âŒ ×”×ª××•× ×” ×œ× ×™×©×¨×”\n",
      "âœ” ×ª××•× ×” × ×©××¨×”: captured_face_1746577388.jpg\n",
      "âœ” ×ª××•× ×” × ×©××¨×”: captured_face_1746577406.jpg\n",
      "âœ” ×ª××•× ×” × ×©××¨×”: captured_face_1746577414.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import time\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True)\n",
    "\n",
    "model_points = np.array([\n",
    "    [0.0, 0.0, 0.0],\n",
    "    [-30.0, -30.0, -30.0],\n",
    "    [30.0, -30.0, -30.0],\n",
    "    [-25.0, 30.0, -30.0],\n",
    "    [25.0, 30.0, -30.0],\n",
    "    [0.0, 70.0, -50.0],\n",
    "])\n",
    "\n",
    "def get_image_points(landmarks, w, h):\n",
    "    return np.array([\n",
    "        [landmarks[1].x * w, landmarks[1].y * h],\n",
    "        [landmarks[33].x * w, landmarks[33].y * h],\n",
    "        [landmarks[263].x * w, landmarks[263].y * h],\n",
    "        [landmarks[61].x * w, landmarks[61].y * h],\n",
    "        [landmarks[291].x * w, landmarks[291].y * h],\n",
    "        [landmarks[199].x * w, landmarks[199].y * h],\n",
    "    ], dtype=np.float64)\n",
    "\n",
    "def estimate_angles(image):\n",
    "    h, w = image.shape[:2]\n",
    "    results = face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    if not results.multi_face_landmarks:\n",
    "        return None\n",
    "    landmarks = results.multi_face_landmarks[0].landmark\n",
    "    image_points = get_image_points(landmarks, w, h)\n",
    "\n",
    "    focal_length = w\n",
    "    center = (w / 2, h / 2)\n",
    "    camera_matrix = np.array([\n",
    "        [focal_length, 0, center[0]],\n",
    "        [0, focal_length, center[1]],\n",
    "        [0, 0, 1]\n",
    "    ], dtype=\"double\")\n",
    "\n",
    "    dist_coeffs = np.zeros((4, 1))\n",
    "    _, rvec, _ = cv2.solvePnP(model_points, image_points, camera_matrix, dist_coeffs)\n",
    "    rotation_mat, _ = cv2.Rodrigues(rvec)\n",
    "    angles, _, _, _, _, _ = cv2.RQDecomp3x3(rotation_mat)\n",
    "    return angles  # pitch, yaw, roll\n",
    "\n",
    "def is_straight(pitch, yaw, roll, tol=15):  # ×”×’×“×œ×ª ×˜×•×œ×¨× ×¡\n",
    "    # ×‘×˜×•×œ×¨× ×¡ ×’×‘×•×” ×™×•×ª×¨ × ×•×›×œ ×œ×”×ª××™× ××ª ×–×” ×œ××¦×™××•×ª\n",
    "    return abs(pitch) < tol and abs(yaw) < tol and abs(roll) < tol\n",
    "\n",
    "def draw_center_box(frame):\n",
    "    h, w = frame.shape[:2]\n",
    "    box_w, box_h = int(w * 0.4), int(h * 0.6)\n",
    "    x1, y1 = (w - box_w) // 2, (h - box_h) // 2\n",
    "    x2, y2 = x1 + box_w, y1 + box_h\n",
    "    cv2.rectangle(frame, (x1, y1), (x2, y2), (100, 255, 100), 2)\n",
    "\n",
    "def process_image(image):\n",
    "    angles = estimate_angles(image)\n",
    "    if angles:\n",
    "        pitch, yaw, roll = angles\n",
    "        straight = is_straight(pitch, yaw, roll)\n",
    "        print(f\"Pitch={pitch:.1f}, Yaw={yaw:.1f}, Roll={roll:.1f}, Straight={straight}\")\n",
    "        if straight:\n",
    "            filename = f\"valid_face_{int(time.time())}.jpg\"\n",
    "            cv2.imwrite(filename, image)\n",
    "            print(f\"âœ” ×ª××•× ×” × ×©××¨×”: {filename}\")\n",
    "        else:\n",
    "            print(\"âŒ ×”×ª××•× ×” ×œ× ×™×©×¨×”\")\n",
    "    else:\n",
    "        print(\"âŒ ×œ× ×–×•×”×” ×¤× ×™×\")\n",
    "\n",
    "def upload_image():\n",
    "    path = filedialog.askopenfilename()\n",
    "    if path:\n",
    "        image = cv2.imread(path)\n",
    "        process_image(image)\n",
    "\n",
    "def capture_from_camera():\n",
    "    face_mesh_camera = mp_face_mesh.FaceMesh(static_image_mode=False)\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        draw_center_box(frame)\n",
    "        angles = estimate_angles(frame)\n",
    "        if angles:\n",
    "            pitch, yaw, roll = angles\n",
    "            aligned = is_straight(pitch, yaw, roll)\n",
    "            color = (0, 255, 0) if aligned else (0, 0, 255)\n",
    "            msg = \"âœ… ××•×›×Ÿ ×œ×¦×™×œ×•×\" if aligned else \"âŒ ×œ× ××•×›×Ÿ\"\n",
    "            cv2.putText(frame, msg, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "            if aligned:\n",
    "                filename = f\"captured_face_{int(time.time())}.jpg\"\n",
    "                cv2.imwrite(filename, frame)\n",
    "                print(f\"âœ” ×ª××•× ×” × ×©××¨×”: {filename}\")\n",
    "                break\n",
    "\n",
    "        cv2.imshow(\"××¦×œ××”\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# GUI ×œ×‘×—×™×¨×”\n",
    "root = tk.Tk()\n",
    "root.title(\"×‘×—×™×¨×ª ××§×•×¨ ×ª××•× ×”\")\n",
    "root.geometry(\"300x100\")\n",
    "\n",
    "btn1 = tk.Button(root, text=\"ğŸ“· ×¦×™×œ×•× ×‘××¦×œ××”\", command=capture_from_camera)\n",
    "btn1.pack(pady=10)\n",
    "\n",
    "btn2 = tk.Button(root, text=\"ğŸ–¼ ×”×¢×œ××ª ×ª××•× ×” ××”××—×©×‘\", command=upload_image)\n",
    "btn2.pack()\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfd9414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ” ×ª××•× ×” × ×©××¨×”: captured_face_1746577752.jpg\n",
      "âœ” ×ª××•× ×” × ×©××¨×”: captured_face_1746577774.jpg\n",
      "âœ” ×ª××•× ×” × ×©××¨×”: captured_face_1746577781.jpg\n",
      "âœ” ×ª××•× ×” × ×©××¨×”: captured_face_1746577786.jpg\n",
      "âœ” ×ª××•× ×” × ×©××¨×”: captured_face_1746577789.jpg\n",
      "Pitch=-22.4, Yaw=-2.2, Roll=-2.7, LookingForward=False\n",
      "âŒ ×”×¤× ×™× ×œ× ×™×©×¨×•×ª ××• ×”××‘×˜ ×œ× ×§×“×™××”\n",
      "Pitch=-24.1, Yaw=-0.7, Roll=-0.6, LookingForward=False\n",
      "âŒ ×”×¤× ×™× ×œ× ×™×©×¨×•×ª ××• ×”××‘×˜ ×œ× ×§×“×™××”\n",
      "Pitch=-5.6, Yaw=-1.9, Roll=0.2, LookingForward=True\n",
      "âœ” ×ª××•× ×” × ×©××¨×”: valid_face_1746577814.jpg\n",
      "Pitch=-12.7, Yaw=-0.4, Roll=-0.4, LookingForward=False\n",
      "âŒ ×”×¤× ×™× ×œ× ×™×©×¨×•×ª ××• ×”××‘×˜ ×œ× ×§×“×™××”\n",
      "Pitch=15.2, Yaw=-1.4, Roll=-0.9, LookingForward=False\n",
      "âŒ ×”×¤× ×™× ×œ× ×™×©×¨×•×ª ××• ×”××‘×˜ ×œ× ×§×“×™××”\n",
      "Pitch=-38.5, Yaw=-0.9, Roll=-3.3, LookingForward=False\n",
      "âŒ ×”×¤× ×™× ×œ× ×™×©×¨×•×ª ××• ×”××‘×˜ ×œ× ×§×“×™××”\n",
      "Pitch=23.0, Yaw=0.5, Roll=0.3, LookingForward=False\n",
      "âŒ ×”×¤× ×™× ×œ× ×™×©×¨×•×ª ××• ×”××‘×˜ ×œ× ×§×“×™××”\n",
      "Pitch=0.2, Yaw=-1.5, Roll=-0.2, LookingForward=True\n",
      "âœ” ×ª××•× ×” × ×©××¨×”: valid_face_1746577851.jpg\n",
      "Pitch=-23.6, Yaw=1.4, Roll=0.3, LookingForward=False\n",
      "âŒ ×”×¤× ×™× ×œ× ×™×©×¨×•×ª ××• ×”××‘×˜ ×œ× ×§×“×™××”\n",
      "Pitch=38.8, Yaw=-2.1, Roll=-1.7, LookingForward=False\n",
      "âŒ ×”×¤× ×™× ×œ× ×™×©×¨×•×ª ××• ×”××‘×˜ ×œ× ×§×“×™××”\n",
      "Pitch=6.1, Yaw=-1.6, Roll=-0.4, LookingForward=True\n",
      "âœ” ×ª××•× ×” × ×©××¨×”: valid_face_1746577866.jpg\n",
      "Pitch=21.8, Yaw=-1.5, Roll=-0.2, LookingForward=False\n",
      "âŒ ×”×¤× ×™× ×œ× ×™×©×¨×•×ª ××• ×”××‘×˜ ×œ× ×§×“×™××”\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdf164f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ” ×ª××•× ×” × ×©××¨×”: captured_face_1746609033.jpg\n",
      "âœ” ×ª××•× ×” × ×©××¨×”: captured_face_1746609040.jpg\n",
      "âœ” ×ª××•× ×” × ×©××¨×”: captured_face_1746609048.jpg\n",
      "âœ” ×ª××•× ×” × ×©××¨×”: captured_face_1746609093.jpg\n",
      "âœ” ×ª××•× ×” × ×©××¨×”: captured_face_1746609101.jpg\n",
      "âœ” ×ª××•× ×” × ×©××¨×”: captured_face_1746609110.jpg\n",
      "âœ” ×ª××•× ×” × ×©××¨×”: captured_face_1746609124.jpg\n",
      "âœ” ×ª××•× ×” × ×©××¨×”: captured_face_1746609131.jpg\n",
      "âœ” ×ª××•× ×” × ×©××¨×”: captured_face_1746609142.jpg\n",
      "âœ” ×ª××•× ×” × ×©××¨×”: captured_face_1746609152.jpg\n",
      "âœ” ×ª××•× ×” × ×©××¨×”: captured_face_1746609157.jpg\n",
      "âœ” ×ª××•× ×” × ×©××¨×”: captured_face_1746609167.jpg\n",
      "Pitch=-7.8, Yaw=6.9, Roll=-3.7, Straight=True, Gaze=True\n",
      "âœ” ×ª××•× ×” × ×©××¨×”: valid_face_1746609182.jpg\n",
      "Pitch=1.7, Yaw=-1.0, Roll=0.3, Straight=True, Gaze=True\n",
      "âœ” ×ª××•× ×” × ×©××¨×”: valid_face_1746609190.jpg\n",
      "Pitch=-7.5, Yaw=6.8, Roll=-3.6, Straight=True, Gaze=True\n",
      "âœ” ×ª××•× ×” × ×©××¨×”: valid_face_1746609202.jpg\n",
      "Pitch=-24.9, Yaw=2.2, Roll=179.2, Straight=False, Gaze=False\n",
      "âŒ ×”×ª××•× ×” ×œ× ×™×©×¨×” ××• ×©×”××‘×˜ ×œ× ×œ××¦×œ××”\n",
      "Pitch=-27.0, Yaw=9.4, Roll=-0.6, Straight=False, Gaze=True\n",
      "âŒ ×”×ª××•× ×” ×œ× ×™×©×¨×” ××• ×©×”××‘×˜ ×œ× ×œ××¦×œ××”\n",
      "Pitch=-22.4, Yaw=1.7, Roll=-0.3, Straight=False, Gaze=True\n",
      "âŒ ×”×ª××•× ×” ×œ× ×™×©×¨×” ××• ×©×”××‘×˜ ×œ× ×œ××¦×œ××”\n",
      "Pitch=-20.3, Yaw=2.8, Roll=1.7, Straight=False, Gaze=True\n",
      "âŒ ×”×ª××•× ×” ×œ× ×™×©×¨×” ××• ×©×”××‘×˜ ×œ× ×œ××¦×œ××”\n",
      "Pitch=-36.4, Yaw=-0.1, Roll=-3.1, Straight=False, Gaze=True\n",
      "âŒ ×”×ª××•× ×” ×œ× ×™×©×¨×” ××• ×©×”××‘×˜ ×œ× ×œ××¦×œ××”\n",
      "Pitch=-23.1, Yaw=-1.2, Roll=-2.3, Straight=False, Gaze=True\n",
      "âŒ ×”×ª××•× ×” ×œ× ×™×©×¨×” ××• ×©×”××‘×˜ ×œ× ×œ××¦×œ××”\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import time\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh_static = mp_face_mesh.FaceMesh(static_image_mode=True, refine_landmarks=True)\n",
    "face_mesh_camera = mp_face_mesh.FaceMesh(static_image_mode=False, refine_landmarks=True)\n",
    "\n",
    "# × ×§×•×“×•×ª ×ª×œ×ª ×××“×™×•×ª ×©×œ ×”×¨××©\n",
    "model_points = np.array([\n",
    "    [0.0, 0.0, 0.0],\n",
    "    [-30.0, -30.0, -30.0],\n",
    "    [30.0, -30.0, -30.0],\n",
    "    [-25.0, 30.0, -30.0],\n",
    "    [25.0, 30.0, -30.0],\n",
    "    [0.0, 70.0, -50.0],\n",
    "])\n",
    "\n",
    "def get_image_points(landmarks, w, h):\n",
    "    return np.array([\n",
    "        [landmarks[1].x * w, landmarks[1].y * h],\n",
    "        [landmarks[33].x * w, landmarks[33].y * h],\n",
    "        [landmarks[263].x * w, landmarks[263].y * h],\n",
    "        [landmarks[61].x * w, landmarks[61].y * h],\n",
    "        [landmarks[291].x * w, landmarks[291].y * h],\n",
    "        [landmarks[199].x * w, landmarks[199].y * h],\n",
    "    ], dtype=np.float64)\n",
    "\n",
    "def estimate_angles(image, mesh_model):\n",
    "    h, w = image.shape[:2]\n",
    "    results = mesh_model.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    if not results.multi_face_landmarks:\n",
    "        return None, None\n",
    "    landmarks = results.multi_face_landmarks[0].landmark\n",
    "    image_points = get_image_points(landmarks, w, h)\n",
    "    focal_length = w\n",
    "    center = (w / 2, h / 2)\n",
    "    camera_matrix = np.array([\n",
    "        [focal_length, 0, center[0]],\n",
    "        [0, focal_length, center[1]],\n",
    "        [0, 0, 1]\n",
    "    ], dtype=\"double\")\n",
    "    dist_coeffs = np.zeros((4, 1))\n",
    "    _, rvec, _ = cv2.solvePnP(model_points, image_points, camera_matrix, dist_coeffs)\n",
    "    rotation_mat, _ = cv2.Rodrigues(rvec)\n",
    "    angles, _, _, _, _, _ = cv2.RQDecomp3x3(rotation_mat)\n",
    "    return angles, landmarks\n",
    "\n",
    "def is_straight(pitch, yaw, roll, tol=10):\n",
    "    return abs(pitch) < tol and abs(yaw) < tol and abs(roll) < tol\n",
    "\n",
    "def is_gaze_forward(landmarks, w):\n",
    "    try:\n",
    "        # ×¢×™×Ÿ ×™××™×Ÿ\n",
    "        re_left = landmarks[33].x * w\n",
    "        re_right = landmarks[133].x * w\n",
    "        re_center = landmarks[468].x * w\n",
    "        re_ratio = (re_center - re_left) / (re_right - re_left)\n",
    "\n",
    "        # ×¢×™×Ÿ ×©×××œ\n",
    "        le_left = landmarks[362].x * w\n",
    "        le_right = landmarks[263].x * w\n",
    "        le_center = landmarks[473].x * w\n",
    "        le_ratio = (le_center - le_left) / (le_right - le_left)\n",
    "\n",
    "        return 0.35 < re_ratio < 0.65 and 0.35 < le_ratio < 0.65\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def draw_center_box(frame):\n",
    "    h, w = frame.shape[:2]\n",
    "    box_w, box_h = int(w * 0.4), int(h * 0.6)\n",
    "    x1, y1 = (w - box_w) // 2, (h - box_h) // 2\n",
    "    x2, y2 = x1 + box_w, y1 + box_h\n",
    "    cv2.rectangle(frame, (x1, y1), (x2, y2), (100, 255, 100), 2)\n",
    "\n",
    "def process_image(image):\n",
    "    h, w = image.shape[:2]\n",
    "    angles, landmarks = estimate_angles(image, face_mesh_static)\n",
    "    if angles and landmarks:\n",
    "        pitch, yaw, roll = angles\n",
    "        straight = is_straight(pitch, yaw, roll)\n",
    "        gaze = is_gaze_forward(landmarks, w)\n",
    "        print(f\"Pitch={pitch:.1f}, Yaw={yaw:.1f}, Roll={roll:.1f}, Straight={straight}, Gaze={gaze}\")\n",
    "        if straight and gaze:\n",
    "            filename = f\"valid_face_{int(time.time())}.jpg\"\n",
    "            cv2.imwrite(filename, image)\n",
    "            print(f\"âœ” ×ª××•× ×” × ×©××¨×”: {filename}\")\n",
    "        else:\n",
    "            print(\"âŒ ×”×ª××•× ×” ×œ× ×™×©×¨×” ××• ×©×”××‘×˜ ×œ× ×œ××¦×œ××”\")\n",
    "    else:\n",
    "        print(\"âŒ ×œ× ×–×•×”×” ×¤× ×™×\")\n",
    "\n",
    "def upload_image():\n",
    "    path = filedialog.askopenfilename()\n",
    "    if path:\n",
    "        image = cv2.imread(path)\n",
    "        process_image(image)\n",
    "\n",
    "def capture_from_camera():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        draw_center_box(frame)\n",
    "        h, w = frame.shape[:2]\n",
    "        angles, landmarks = estimate_angles(frame, face_mesh_camera)\n",
    "        if angles and landmarks:\n",
    "            pitch, yaw, roll = angles\n",
    "            straight = is_straight(pitch, yaw, roll)\n",
    "            gaze = is_gaze_forward(landmarks, w)\n",
    "            color = (0, 255, 0) if straight and gaze else (0, 0, 255)\n",
    "            msg = \"âœ… ××•×›×Ÿ ×œ×¦×™×œ×•×\" if straight and gaze else \"âŒ ×œ× ××•×›×Ÿ\"\n",
    "            cv2.putText(frame, msg, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "            if straight and gaze:\n",
    "                filename = f\"captured_face_{int(time.time())}.jpg\"\n",
    "                cv2.imwrite(filename, frame)\n",
    "                print(f\"âœ” ×ª××•× ×” × ×©××¨×”: {filename}\")\n",
    "                break\n",
    "        cv2.imshow(\"××¦×œ××”\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# GUI\n",
    "root = tk.Tk()\n",
    "root.title(\"×‘×—×™×¨×ª ××§×•×¨ ×ª××•× ×”\")\n",
    "root.geometry(\"300x100\")\n",
    "\n",
    "btn1 = tk.Button(root, text=\"ğŸ“· ×¦×™×œ×•× ×‘××¦×œ××”\", command=capture_from_camera)\n",
    "btn1.pack(pady=10)\n",
    "\n",
    "btn2 = tk.Button(root, text=\"ğŸ–¼ ×”×¢×œ××ª ×ª××•× ×” ××”××—×©×‘\", command=upload_image)\n",
    "btn2.pack()\n",
    "\n",
    "root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
